{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Recommend_Collaborative_Filtering.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kPt5q27L5557"},"source":["## Recommender System - Collaborative Filtering"]},{"cell_type":"markdown","metadata":{"id":"p0-YhEpP_Ds-"},"source":["### Setup"]},{"cell_type":"markdown","metadata":{"id":"Zsj5WYpR9QId"},"source":["Let's setup Spark on your Colab environment.  Run the cell below!"]},{"cell_type":"code","metadata":{"id":"k-qHai2252mI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619316528468,"user_tz":300,"elapsed":56357,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}},"outputId":"a8cc65bd-d600-4356-c690-768b3c7726d5"},"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 70kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 38.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=360923801121be9ef0eeea937d2a592aacbd1ed5b63f67376b199c0f9295325b\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n","Need to get 36.5 MB of archives.\n","After this operation, 143 MB of additional disk space will be used.\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","(Reading database ... 160690 files and directories currently installed.)\n","Preparing to unpack .../openjdk-8-jre-headless_8u282-b08-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u282-b08-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PUUjUvXe3Sjk"},"source":["Now we authenticate a Google Drive client to download the filea we will be processing in our Spark job.\n","\n","**Make sure to follow the interactive instructions.**"]},{"cell_type":"code","metadata":{"id":"lRElWs_x2mGh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619316559923,"user_tz":300,"elapsed":17441,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}},"outputId":"26bd1826-f755-40eb-bf72-bf2dbe6885f2"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import pandas as pd\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","cur_path = \"/content/drive/MyDrive/class/big_data/final-project/\"\n","os.chdir(cur_path)\n","!pwd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/class/big_data/final-project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"twk-K-jilWK7","executionInfo":{"status":"ok","timestamp":1619316579762,"user_tz":300,"elapsed":384,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import pyspark\n","from pyspark.sql import *\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BtrJlMBt1Ela"},"source":["Let's initialize the Spark context."]},{"cell_type":"code","metadata":{"id":"YdIlW8F-0Ikr","executionInfo":{"status":"ok","timestamp":1619316585934,"user_tz":300,"elapsed":4767,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}}},"source":["# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = pyspark.SparkContext(conf=conf)\n","spark = SparkSession.builder.getOrCreate()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YqovskkH1DmC"},"source":["You can easily check the current version and get the link of the web interface. In the Spark UI, you can monitor the progress of your job and debug the performance bottlenecks (if your Colab is running with a **local runtime**)."]},{"cell_type":"code","metadata":{"id":"DueQggJc1DDk","colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"status":"ok","timestamp":1617934346360,"user_tz":300,"elapsed":1453,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}},"outputId":"47d280bc-7ecd-43c9-a169-158f389851ee"},"source":["spark"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://52baf925e877:4050\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fb1056d5f90>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"Iid7lXcG1CY8"},"source":["If you are running this Colab on the Google hosted runtime, the cell below will create a *ngrok* tunnel which will allow you to still check the Spark UI."]},{"cell_type":"markdown","metadata":{"id":"kAYRX2PMm0L6"},"source":["### Data Loading"]},{"cell_type":"markdown","metadata":{"id":"7hXdMR6wnEIM"},"source":["\n","\n","We load the ratings data in a 70%-30% ```training```/```test``` split"]},{"cell_type":"code","metadata":{"id":"wYrSaCyYNPxL","executionInfo":{"status":"ok","timestamp":1619316636141,"user_tz":300,"elapsed":42924,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}}},"source":["# load data\n","data = spark.read.csv('data/rating_1.csv',inferSchema=True,header=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"mX23DVkINaf-","executionInfo":{"status":"ok","timestamp":1619316640196,"user_tz":300,"elapsed":431,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}}},"source":["# split data\n","(training, test) = data.randomSplit([0.7, 0.3])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOzayU1HNhbC"},"source":["# train the model\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","# Build the recommendation model using ALS on the training data\n","als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n","model = als.fit(training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yvUL2rJONp5H"},"source":["# predict\n","predictions = model.transform(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQQ7p1XUPEye","executionInfo":{"status":"ok","timestamp":1618099464036,"user_tz":300,"elapsed":123000,"user":{"displayName":"Can Luo","photoUrl":"","userId":"01636766564641353094"}},"outputId":"423243b1-4c0e-45f4-c4bf-e08aeb1c6811"},"source":["# evaluate \n","evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n","rmse = evaluator.evaluate(predictions)\n","print(\"Root-mean-square error = \" + str(rmse))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Root-mean-square error = 0.9606348379331474\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O7AkCs5qPutZ"},"source":["# save the model\n","model.save('svd.model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"of8zl3zjQPYg"},"source":["# here is how you can use the saved model\n","from pyspark.ml.recommendation import ALS, ALSModel\n","persistedModel = ALSModel.load('svd.model')\n","predictions_new = persistedModel.transform(test)\n","evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n","rmse = evaluator.evaluate(predictions_new)\n","print(\"Root-mean-square error = \" + str(rmse))"],"execution_count":null,"outputs":[]}]}